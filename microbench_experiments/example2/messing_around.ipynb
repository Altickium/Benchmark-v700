{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data framework: the basic paradigm\n",
    "\n",
    "user implements one function define_experiment\n",
    "\n",
    "then runs run_experiments.py\n",
    "\n",
    "it runs potentially many experimental trials (over all defined configurations), captures output, builds a sqlite database, queries it, produces plots, produces html pages to display plots...\n",
    "\n",
    "also lots of tools to do querying, plot generation and analysis in jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the following code cell before any others\n",
    "\n",
    "It does basic initialization for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "print(\"Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 'hello world' of `run_experiments.sh`\n",
    "\n",
    "defining a trivial experiment that compiles and runs a single command once and saves the output.\n",
    "\n",
    "we do run_in_jupyter and pass define_experiment. could save define_experiment in a python file and run the equivalent run_experiments.sh command..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')     ## working dir for compiling\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin') ## working dir for running\n",
    "    set_cmd_compile  (exp_dict, 'make brown_ext_abtree_lf.debra')\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/libjemalloc.so numactl --interleave=all time ./brown_ext_abtree_lf.debra -nwork 1 -nprefill 1 -insdel 5 5 -k 200000 -t 1000')\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production')\n",
    "# if the define_experiment() function above were saved in a file myexp.py,\n",
    "# then the run_in_jupyter line above is equivalent to running shell command:\n",
    "#   ../../tools/data_framework/run_experiment.py myexp.py --production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the same thing from the command line!\n",
    "\n",
    "copy the define_experiment function definition above into a file called `myexp.py` (in this directory) and then run `../../tools/data_framework/run_experiment.py myexp.py --production` in the shell (in this directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Re)running results without compiling\n",
    "\n",
    "introduce rerunning experiments without compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')     ## working dir for compiling\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin') ## working dir for running\n",
    "    set_cmd_compile  (exp_dict, 'make brown_ext_abtree_lf.debra')\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/libjemalloc.so numactl --interleave=all time ./brown_ext_abtree_lf.debra -nwork 1 -nprefill 1 -insdel 5 5 -k 200000 -t 1000')\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile')\n",
    "# equiv cmd: [...]/run_experiment.py myexp.py --production --no-compile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data files (captured stdout/err)\n",
    "\n",
    "introduce concept of data files (capturing the output of the run)\n",
    "\n",
    "this is the output of that one run command we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(shell_to_str('cat data/data000001.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running with varying parameters\n",
    "\n",
    "of course running one command isn't very interesting...\n",
    "\n",
    "introduce run params\n",
    "\n",
    "    ## add parameters that you want your experiments to be run with.\n",
    "    ## your program will be run once for each set of values in the CROSS PRODUCT of all parameters.\n",
    "    ## (i.e., we will run your program with every combination of parameters)\n",
    "\n",
    "introduce replacement strings: {DS_TYPENAME}\n",
    "\n",
    "note we now need to compile ALL of the binaries we want to run. we just change our make command to compile everything...\n",
    "\n",
    "    ## you can use any of the run params you define to dynamically replace {_tokens_like_this} in strings. for example, we can include {DS_TYPENAME} in our run command, and it will be replaced by the current value of {DS_TYPENAME} (that's right, we can run different commands based on the current value of DS_TYPENAME)\n",
    "    ## you can also get the paths to key directories by using:\n",
    "    ##      {__dir_compile}\n",
    "    ##      {__dir_run}\n",
    "    ##      {__dir_data}\n",
    "    ##\n",
    "    ## the following replacement token is also defined for you:\n",
    "    ##      {__step}            the number of runs done so far, padded to six digits with leading zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin')\n",
    "    set_cmd_compile  (exp_dict, 'make -j6') ## -j specifies how many threads to compile with\n",
    "\n",
    "    add_run_param    (exp_dict, 'DS_TYPENAME', ['brown_ext_ist_lf', 'brown_ext_abtree_lf', 'bronson_pext_bst_occ'])\n",
    "\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/libjemalloc.so numactl --interleave=all time ./{DS_TYPENAME}.debra -nwork 1 -nprefill 1 -insdel 5 5 -k 200000 -t 1000')\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data fields from captured stdout/err\n",
    "\n",
    "note 3 data files were produced this time... one for each value of `DS_TYPENAME`. let's put those data files to use by specifying that we want to *extract* some text from each data file.\n",
    "\n",
    "in particular, let's extract a line of the form \"`DS_TYPENAME=...`\" and a line of the form \"`total_throughput=...`\" from each data file. (you can find such lines in the data file above if you like.)\n",
    "\n",
    "extracted data is stored in a sqlite database `data/output_database.sqlite` in a table called `data`. (each field name passed to `add_data_field` becomes a **column** in `data`.)\n",
    "\n",
    "to do this, we call `add_data_field()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin')\n",
    "    set_cmd_compile  (exp_dict, 'make -j6')\n",
    "\n",
    "    add_run_param    (exp_dict, 'DS_TYPENAME', ['brown_ext_ist_lf', 'brown_ext_abtree_lf', 'bronson_pext_bst_occ'])\n",
    "\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/libjemalloc.so numactl --interleave=all time ./{DS_TYPENAME}.debra -nwork 1 -nprefill 1 -insdel 5 5 -k 200000 -t 1000')\n",
    "\n",
    "    add_data_field   (exp_dict, 'DS_TYPENAME')\n",
    "    add_data_field   (exp_dict, 'total_throughput')\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the database\n",
    "\n",
    "Note that we can simply **access** the last database we created, *WITHOUT rerunning* any experiments, by adding `--no-run --no-createdb` to `cmdline_args` in our `run_in_jupyter` call.\n",
    "\n",
    "Also note that you can accomplish the same thing from the **command line** by running `../../tools/data_framework/run_experiments.py` with the **same** `cmdline_args`. However, since you can't pass your `define_experiments` function as a command line argument, you have to save it in a `.py` file and pass the name of that file as the first argument to `run_experiments.py`.\n",
    "\n",
    "To query the database, we can use function `select_to_dataframe(sql_string)` with a suitable `sql_string`. There are many other powerful functions included for querying and plotting data, but those are covered in `microbench_experiments/example/instructions_data.ipynb`. In **this** notebook we are focusing on the design of the `define_experiment` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile --no-run --no-createdb')\n",
    "df = select_to_dataframe('select * from data')\n",
    "df\n",
    "\n",
    "# run_in_jupyter call above has equivalent command:\n",
    "# [...]/run_experiment.py myexp.py --production --no-compile --no-run --no-createdb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppressing logging output in `run_in_jupyter`\n",
    "\n",
    "If you want to call `run_in_jupyter` without seeing the logs copied to stdout, you can disable the log output by calling `disable_tee_stdout()`. Note that logs will still occur, but the output will **only** go to the log file `output_log.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "disable_tee_stdout()\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile --no-run --no-createdb')\n",
    "df = select_to_dataframe('select * from data')\n",
    "enable_tee_stdout() ## remember to enable, or you won't get output where you expect it...\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running multiple trials\n",
    "\n",
    "    ## if you want to perform repeated trials of each experimental configuration, add a run_param called \"__trial\"\n",
    "    ##     and specify a list of trial numbers (as below).\n",
    "    ##\n",
    "    ## (the run_param doesn't *need* to be called __trials exactly, but if it is called __trials exactly,\n",
    "    ##     then extra sanity checks will be performed to verify, for example, that each data point in a graphical plot\n",
    "    ##     represents the average of precisely as many experimental runs as there are entries in the __trials list.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin')\n",
    "    set_cmd_compile  (exp_dict, 'make -j6')\n",
    "\n",
    "    add_run_param    (exp_dict, '__trials', [1, 2, 3])\n",
    "    add_run_param    (exp_dict, 'DS_TYPENAME', ['brown_ext_ist_lf', 'brown_ext_abtree_lf', 'bronson_pext_bst_occ'])\n",
    "\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/libjemalloc.so numactl --interleave=all time ./{DS_TYPENAME}.debra -nwork 1 -nprefill 1 -insdel 5 5 -k 200000 -t 1000')\n",
    "\n",
    "    add_data_field   (exp_dict, 'DS_TYPENAME')\n",
    "    add_data_field   (exp_dict, 'total_throughput')\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the data (to see the multiple trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_to_dataframe('select * from data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractors: mining data from arbitrary text\n",
    "\n",
    "    ## by default, a field \"XYZ\" will be fetched from each data file using extractor grep_line,\n",
    "    ##      which greps (searches) for a line of the form \"XYZ=[arbitrary string]\\n\"\n",
    "    ##\n",
    "    ## if your field is not stored in that format, you can specify a custom \"extractor\" function,\n",
    "    ##      as we do in our example \"get_maxres\" BELOW, to extract the max resident size\n",
    "    ##      from the 6th space-separated column of the output of the linux \"time\" command\n",
    "    ##\n",
    "    ## also note: each of these fields becomes a replacement token, e.g., {PAPI_L3_TCM}.\n",
    "    ##\n",
    "    ## the following special fields are also defined for you:\n",
    "    ##      {__step}            the number of runs done so far, padded to six digits with leading zeros\n",
    "    ##      {__cmd_run}         your cmd_run string with any tokens replaced appropriately for this run\n",
    "    ##      {__file_data}       the output filename for the current run's data\n",
    "    ##      {__path_data}       the relative path to the output file for the current run's data\n",
    "    ##      {__hostname}        the result of running the hostname command on the machine\n",
    "    ##      {__id}              a unique row ID\n",
    "\n",
    "    ## note: in the following, defaults are \"validator=is_nonempty\" and \"extractor=grep_line\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text output we are *trying* to extract max resident size from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## text output we are trying to extract max resident size from in MB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractor that accomplishes this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using** this extractor in `define_experiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validators: *checking* extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the results (for data with <ins>3 dimensions</ins>)\n",
    "\n",
    "introduce `add_plot_set`\n",
    "\n",
    "need command line arg `--do-plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_tools    (exp_dict, os.getcwd() + '/../../tools') ## tools library for plotting\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin')\n",
    "    set_cmd_compile  (exp_dict, 'make bin_dir={__dir_run} -j6')\n",
    "\n",
    "    add_run_param    (exp_dict, '__trials', [1, 2])\n",
    "    add_run_param    (exp_dict, 'TOTAL_THREADS', [1, 2, 4, 8])\n",
    "    add_run_param    (exp_dict, 'DS_TYPENAME', ['brown_ext_ist_lf', 'brown_ext_abtree_lf', 'bronson_pext_bst_occ'])\n",
    "\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/libjemalloc.so numactl --interleave=all time ./{DS_TYPENAME}.debra -nwork {TOTAL_THREADS} -nprefill {TOTAL_THREADS} -insdel 5 5 -k 200000 -t 1000')\n",
    "\n",
    "    add_data_field   (exp_dict, 'DS_TYPENAME' , validator=is_run_param('DS_TYPENAME'))\n",
    "    add_data_field   (exp_dict, 'TOTAL_THREADS', validator=is_run_param('TOTAL_THREADS'))\n",
    "    add_data_field   (exp_dict, 'total_throughput' , coltype='INTEGER' , validator=is_positive)\n",
    "\n",
    "    add_plot_set( \\\n",
    "            exp_dict \\\n",
    "          , name='throughput.png' \\\n",
    "          , title='Throughput vs data structure' \\\n",
    "          , series='DS_TYPENAME' \\\n",
    "          , x_axis='TOTAL_THREADS' \\\n",
    "          , y_axis='total_throughput' \\\n",
    "          , plot_type='bars' \\\n",
    "          , plot_cmd_args = '--legend-include' \\\n",
    "    )\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile --do-plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's view the data and plot produced by the previous cell\n",
    "\n",
    "(You have to run the previous cell before running the next one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "display(Image('data/throughput.png'))\n",
    "display(select_to_dataframe('select * from data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing *many* plots (for data with <ins>5 dimensions</ins>)\n",
    "\n",
    "let's add a couple of dimensions:\n",
    "- key range (`MAXKEY` in the data file)\n",
    "- update rate (`INS_DEL_FRAC` in the data file)\n",
    "\n",
    "and use them to produce **multiple plots** (one for each combination of values of these dimensions). we do this by specifying `varying_cols_list` in `add_plot_set`.\n",
    "\n",
    "we can also customize the plot file`name`s and `title`s with these parameters.\n",
    "\n",
    "# Showing these plots in a table in an HTML page\n",
    "\n",
    "we also generate an HTML page to show off these grids in a table by invoking `add_page_set`.\n",
    "\n",
    "HTML page construction only occurs if you specify command line argument `--do-pages` to `run_experiment.py`. so, we add this to `run_in_jupyter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_tools    (exp_dict, os.getcwd() + '/../../tools') ## path to tools library\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin')\n",
    "    set_cmd_compile  (exp_dict, 'make bin_dir={__dir_run} -j6')\n",
    "\n",
    "    add_run_param    (exp_dict, '__trials', [1, 2])\n",
    "    add_run_param    (exp_dict, 'TOTAL_THREADS', [1, 2, 4, 8])\n",
    "    add_run_param    (exp_dict, 'DS_TYPENAME', ['brown_ext_ist_lf', 'brown_ext_abtree_lf', 'bronson_pext_bst_occ'])\n",
    "    add_run_param    (exp_dict, 'MAXKEY', [20000, 200000])\n",
    "    add_run_param    (exp_dict, 'INS_DEL_FRAC', [\"0.0 0.0\", \"5.0 5.0\"])\n",
    "\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/libjemalloc.so numactl --interleave=all time ./{DS_TYPENAME}.debra -nwork {TOTAL_THREADS} -nprefill {TOTAL_THREADS} -insdel {INS_DEL_FRAC} -k {MAXKEY} -t 1000')\n",
    "\n",
    "    add_data_field   (exp_dict, 'DS_TYPENAME' , validator=is_run_param('DS_TYPENAME'))\n",
    "    add_data_field   (exp_dict, 'TOTAL_THREADS', coltype='INTEGER', validator=is_run_param('TOTAL_THREADS'))\n",
    "    add_data_field   (exp_dict, 'INS_DEL_FRAC', validator=is_run_param('INS_DEL_FRAC'))\n",
    "    add_data_field   (exp_dict, 'MAXKEY', coltype='INTEGER', validator=is_run_param('MAXKEY'))\n",
    "    add_data_field   (exp_dict, 'total_throughput', coltype='INTEGER', validator=is_positive)\n",
    "\n",
    "    ## we place the above legend at the bottom of *each* table by providing \"legend_file\"\n",
    "    add_plot_set( \\\n",
    "            exp_dict \\\n",
    "          , name='throughput-{INS_DEL_FRAC}-{MAXKEY}k.png' \\\n",
    "          , title='{INS_DEL_FRAC} {MAXKEY}k: throughput' \\\n",
    "          , varying_cols_list=['MAXKEY', 'INS_DEL_FRAC'] \\\n",
    "          , series='DS_TYPENAME' \\\n",
    "          , x_axis='TOTAL_THREADS' \\\n",
    "          , y_axis='total_throughput' \\\n",
    "          , plot_type='bars' \\\n",
    "    )\n",
    "\n",
    "    ## render one legend for all plots (since the legend is the same for all).\n",
    "    ## if legend varies from plot to plot, you might enable legends for all plots,\n",
    "    ## or write a custom plotting command that determines what to do, given your data\n",
    "    add_plot_set(exp_dict, name='throughput-legend.png', series='DS_TYPENAME', x_axis='TOTAL_THREADS', y_axis='total_throughput', plot_type='bars', plot_cmd_args='--legend-only --legend-columns 3')\n",
    "\n",
    "    ## we place the above legend at the bottom of *each* table by providing \"legend_file\"\n",
    "    add_page_set( \\\n",
    "            exp_dict \\\n",
    "          , image_files='throughput-{INS_DEL_FRAC}-{MAXKEY}k.png' \\\n",
    "          , name='throughput' \\\n",
    "          , column_field='INS_DEL_FRAC' \\\n",
    "          , row_field='MAXKEY' \\\n",
    "          , legend_file='throughput-legend.png' \\\n",
    "    )\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile --do-plot --do-pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's view the plots produced by the previous cell\n",
    "\n",
    "note you can click on the plots to \"drill down\" into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html('data/throughput.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How about 4 dimensions?\n",
    "\n",
    "Let's removed the `MAXKEY` column / data dimension to reduce the dimensionality of the data to 4.\n",
    "\n",
    "With only one column in the `varying_cols_list` and NO `row_field` specified in `add_page_set`, there will only be one row of plots. (So a strip of plots instead of a grid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_tools    (exp_dict, os.getcwd() + '/../../tools') ## path to tools library\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin')\n",
    "    set_cmd_compile  (exp_dict, 'make bin_dir={__dir_run} -j6')\n",
    "\n",
    "    add_run_param    (exp_dict, '__trials', [1, 2])\n",
    "    add_run_param    (exp_dict, 'TOTAL_THREADS', [1, 2, 4, 8])\n",
    "    add_run_param    (exp_dict, 'DS_TYPENAME', ['brown_ext_ist_lf', 'brown_ext_abtree_lf', 'bronson_pext_bst_occ'])\n",
    "    add_run_param    (exp_dict, 'INS_DEL_FRAC', [\"0.0 0.0\", \"5.0 5.0\"])\n",
    "\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/libjemalloc.so numactl --interleave=all time ./{DS_TYPENAME}.debra -nwork {TOTAL_THREADS} -nprefill {TOTAL_THREADS} -insdel {INS_DEL_FRAC} -k 200000 -t 1000')\n",
    "\n",
    "    add_data_field   (exp_dict, 'DS_TYPENAME' , validator=is_run_param('DS_TYPENAME'))\n",
    "    add_data_field   (exp_dict, 'TOTAL_THREADS', coltype='INTEGER', validator=is_run_param('TOTAL_THREADS'))\n",
    "    add_data_field   (exp_dict, 'INS_DEL_FRAC', validator=is_run_param('INS_DEL_FRAC'))\n",
    "    add_data_field   (exp_dict, 'total_throughput', coltype='INTEGER', validator=is_positive)\n",
    "\n",
    "    add_plot_set( \\\n",
    "            exp_dict \\\n",
    "          , name='throughput-{INS_DEL_FRAC}.png' \\\n",
    "          , title='{INS_DEL_FRAC}: throughput' \\\n",
    "          , varying_cols_list=['INS_DEL_FRAC'] \\\n",
    "          , series='DS_TYPENAME' \\\n",
    "          , x_axis='TOTAL_THREADS' \\\n",
    "          , y_axis='total_throughput' \\\n",
    "          , plot_type='bars' \\\n",
    "    )\n",
    "\n",
    "    ## render one legend for all plots (since the legend is the same for all).\n",
    "    ## if legend varies from plot to plot, you might enable legends for all plots,\n",
    "    ## or write a custom plotting command that determines what to do, given your data\n",
    "    add_plot_set(exp_dict, name='throughput-legend.png', series='DS_TYPENAME', x_axis='TOTAL_THREADS', y_axis='total_throughput', plot_type='bars', plot_cmd_args='--legend-only --legend-columns 3')\n",
    "\n",
    "    ## we place the above legend at the bottom of *each* table by providing \"legend_file\"\n",
    "    add_page_set( \\\n",
    "            exp_dict \\\n",
    "          , image_files='throughput-{INS_DEL_FRAC}.png' \\\n",
    "          , name='throughput' \\\n",
    "          , column_field='INS_DEL_FRAC' \\\n",
    "          , legend_file='throughput-legend.png' \\\n",
    "    )\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile --do-plot --do-pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's view the plots produced by the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html('data/throughput.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots and HTML for data with <ins>6 dimensions</ins>\n",
    "\n",
    "note that we could have added more than 2 dimensions of data (resulting in data with 6+ dimensions), listing potentially many fields in `varying_cols_list`, and this simply would have resulted in *more plots*.\n",
    "\n",
    "note that if we had **one** more dimension of data (6 dimensions in total), it could be listed in the keyword argument `table_field`, and **multiple** HTML tables would be rendered in a single HTML page (one for each value of this column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_tools    (exp_dict, os.getcwd() + '/../../tools') ## path to tools library\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin')\n",
    "    set_cmd_compile  (exp_dict, 'make bin_dir={__dir_run} -j6')\n",
    "\n",
    "    add_run_param    (exp_dict, '__trials', [1])\n",
    "    add_run_param    (exp_dict, 'TOTAL_THREADS', [2, 4, 8])\n",
    "    add_run_param    (exp_dict, 'DS_TYPENAME', ['brown_ext_abtree_lf', 'bronson_pext_bst_occ'])\n",
    "    add_run_param    (exp_dict, 'MAXKEY', [20000, 200000])\n",
    "    add_run_param    (exp_dict, 'INS_DEL_FRAC', ['0.0 0.0', '5.0 5.0'])\n",
    "    ## unlike the above four fields,\n",
    "    ## the run command does NOT produce a line of the form 'malloc=[...]'.\n",
    "    ## so, run_experiment.py will APPEND a line of this form to the datafile!\n",
    "    add_run_param    (exp_dict, 'malloc', ['jemalloc', 'mimalloc'])\n",
    "\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/lib{malloc}.so numactl --interleave=all time ./{DS_TYPENAME}.debra -nwork {TOTAL_THREADS} -nprefill {TOTAL_THREADS} -insdel {INS_DEL_FRAC} -k {MAXKEY} -t 1000')\n",
    "\n",
    "    add_data_field   (exp_dict, 'DS_TYPENAME' , validator=is_run_param('DS_TYPENAME'))\n",
    "    add_data_field   (exp_dict, 'TOTAL_THREADS', coltype='INTEGER', validator=is_run_param('TOTAL_THREADS'))\n",
    "    add_data_field   (exp_dict, 'INS_DEL_FRAC', validator=is_run_param('INS_DEL_FRAC'))\n",
    "    add_data_field   (exp_dict, 'MAXKEY', coltype='INTEGER', validator=is_run_param('MAXKEY'))\n",
    "    add_data_field   (exp_dict, 'total_throughput', coltype='INTEGER', validator=is_positive)\n",
    "    add_data_field   (exp_dict, 'malloc', validator=is_run_param('malloc'))\n",
    "\n",
    "    add_plot_set( \\\n",
    "            exp_dict \\\n",
    "          , name='throughput-{malloc}-{INS_DEL_FRAC}-{MAXKEY}.png' \\\n",
    "          , title='{malloc} {INS_DEL_FRAC} {MAXKEY}' \\\n",
    "          , varying_cols_list=['malloc', 'MAXKEY', 'INS_DEL_FRAC'] \\\n",
    "          , series='DS_TYPENAME' \\\n",
    "          , x_axis='TOTAL_THREADS' \\\n",
    "          , y_axis='total_throughput' \\\n",
    "          , plot_type='bars' \\\n",
    "    )\n",
    "\n",
    "    ## render one legend for all plots (since the legend is the same for all).\n",
    "    ## if legend varies from plot to plot, you might enable legends for all plots,\n",
    "    ## or write a custom plotting command that determines what to do, given your data\n",
    "    add_plot_set(exp_dict, name='throughput-legend.png', series='DS_TYPENAME', x_axis='TOTAL_THREADS', y_axis='total_throughput', plot_type='bars', plot_cmd_args='--legend-only --legend-columns 3')\n",
    "\n",
    "    ## note: choice of column / row / table field determines how the HTML page looks -- up to you!\n",
    "    add_page_set( \\\n",
    "            exp_dict \\\n",
    "          , image_files='throughput-{malloc}-{INS_DEL_FRAC}-{MAXKEY}.png' \\\n",
    "          , name='throughput' \\\n",
    "          , column_field='INS_DEL_FRAC' \\\n",
    "          , row_field='MAXKEY' \\\n",
    "          , table_field='malloc' \\\n",
    "          , legend_file='throughput-legend.png' \\\n",
    "    )\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile --do-plot --do-pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's view the data, plots and HTML we produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html('data/throughput.html')\n",
    "display(select_to_dataframe('select * from data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots and HTML for data with <ins>7+ dimensions</ins>\n",
    "\n",
    "if we had MORE than one extra dimension of data (7+ dimensions in total), we could list additional fields in the keyword argument `page_field_list`, which would cause additional HTML pages to be rendered (one for each combination of values for fields in `page_field_list`), and linked together by an `index.htm`. (note that the `name` keyword argument of `page_field_list` must also be modified to reference these fields, in order for multiple HTML files to be created---you must specify what sort of naming convention you'd like the framework to use.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_tools    (exp_dict, os.getcwd() + '/../../tools') ## path to tools library\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/../../microbench/bin')\n",
    "    set_cmd_compile  (exp_dict, 'make bin_dir={__dir_run} -j6')\n",
    "\n",
    "    add_run_param    (exp_dict, '__trials', [1])\n",
    "    add_run_param    (exp_dict, 'TOTAL_THREADS', [2, 8])\n",
    "    add_run_param    (exp_dict, 'DS_TYPENAME', ['brown_ext_abtree_lf', 'bronson_pext_bst_occ'])\n",
    "    add_run_param    (exp_dict, 'MAXKEY', [20000, 200000])\n",
    "    add_run_param    (exp_dict, 'INS_DEL_FRAC', ['0.0 0.0', '5.0 5.0'])\n",
    "    ## unlike the above four fields,\n",
    "    ## the run command does NOT produce a line of the form 'malloc=[...]'.\n",
    "    ## so, run_experiment.py will APPEND a line of this form to the datafile!\n",
    "    add_run_param    (exp_dict, 'malloc', ['jemalloc', 'mimalloc'])\n",
    "    ## ditto for reclaimer\n",
    "    add_run_param    (exp_dict, 'numactl', ['', 'numactl --interleave=all'])\n",
    "\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../lib/lib{malloc}.so {numactl} time ./{DS_TYPENAME}.debra -nwork {TOTAL_THREADS} -nprefill {TOTAL_THREADS} -insdel {INS_DEL_FRAC} -k {MAXKEY} -t 1000')\n",
    "\n",
    "    add_data_field   (exp_dict, 'DS_TYPENAME' , validator=is_run_param('DS_TYPENAME'))\n",
    "    add_data_field   (exp_dict, 'TOTAL_THREADS', coltype='INTEGER', validator=is_run_param('TOTAL_THREADS'))\n",
    "    add_data_field   (exp_dict, 'INS_DEL_FRAC', validator=is_run_param('INS_DEL_FRAC'))\n",
    "    add_data_field   (exp_dict, 'MAXKEY', coltype='INTEGER', validator=is_run_param('MAXKEY'))\n",
    "    add_data_field   (exp_dict, 'total_throughput', coltype='INTEGER', validator=is_positive)\n",
    "    add_data_field   (exp_dict, 'malloc', validator=is_run_param('malloc'))\n",
    "    add_data_field   (exp_dict, 'numactl', validator=is_run_param('numactl'))\n",
    "\n",
    "    add_plot_set( \\\n",
    "            exp_dict \\\n",
    "          , name='throughput-{malloc}-{numactl}-{INS_DEL_FRAC}-{MAXKEY}.png' \\\n",
    "          , title='{INS_DEL_FRAC} {MAXKEY}' \\\n",
    "          , varying_cols_list=['malloc', 'numactl', 'MAXKEY', 'INS_DEL_FRAC'] \\\n",
    "          , series='DS_TYPENAME' \\\n",
    "          , x_axis='TOTAL_THREADS' \\\n",
    "          , y_axis='total_throughput' \\\n",
    "          , plot_type='bars' \\\n",
    "    )\n",
    "\n",
    "    ## render one legend for all plots (since the legend is the same for all).\n",
    "    ## if legend varies from plot to plot, you might enable legends for all plots,\n",
    "    ## or write a custom plotting command that determines what to do, given your data\n",
    "    add_plot_set(exp_dict, name='throughput-legend.png', series='DS_TYPENAME', x_axis='TOTAL_THREADS', y_axis='total_throughput', plot_type='bars', plot_cmd_args='--legend-only --legend-columns 3')\n",
    "\n",
    "    ## we place the above legend at the bottom of *each* table by providing \"legend_file\"\n",
    "    add_page_set( \\\n",
    "            exp_dict \\\n",
    "          , image_files='throughput-{malloc}-{numactl}-{INS_DEL_FRAC}-{MAXKEY}.png' \\\n",
    "          , name='throughput' \\\n",
    "          , column_field='numactl' \\\n",
    "          , row_field='malloc' \\\n",
    "          , table_field='MAXKEY' \\\n",
    "          , page_field_list=['INS_DEL_FRAC'] \\\n",
    "          , legend_file='throughput-legend.png' \\\n",
    "    )\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "run_in_jupyter(define_experiment, cmdline_args='--production --no-compile --no-run --do-plot --do-pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's view the data, plots and HTML we produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html('data/index.html')\n",
    "display(select_to_dataframe('select * from data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's easy to plot *many* value fields vs your `run_params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notebook todo\n",
    "- validators\n",
    "- extractors\n",
    "- testing mode\n",
    "- special reserved data field names\n",
    "- custom output filename pattern, output path\n",
    "- best-effort automated sanity checks\n",
    "- complete control with custom plot function\n",
    "- archival benefits (zip: data, commit id, diffs from commit)\n",
    "\n",
    "may want to support pages with columns covering a list of specific data values (throughput, l3miss, l2miss, cycles, maxresident, etc.)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594215540838",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}